#!/usr/bin/env bash
set -euo pipefail

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏–∑ .env ---
if [ -f .env ]; then
  set -a
  source .env
  set +a
fi

# --- –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (–∏–∑ .env) ---
export MINIO_ROOT_USER
export MINIO_ROOT_PASSWORD
export AIRFLOW_UID=$(id -u)
export IMAGE_TAG
echo "INFO: IMAGE_TAG = ${IMAGE_TAG}"

# --- –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ ---
MINIO_SERVICE_NAME="minio"
REDIS_SERVICE_NAME="redis"
SPARK_MASTER_SERVICE_NAME="spark-master"
SPARK_WORKER_SERVICE_NAME="spark-worker-1"
AIRFLOW_SERVICE_NAME="airflow"
POSTGRES_SERVICE_NAME="postgres"
MLFLOW_SERVICE_NAME="mlflow" # <-- –ò–ó–ú–ï–ù–ï–ù–ò–ï: –î–æ–±–∞–≤–ª–µ–Ω–æ –∏–º—è —Å–µ—Ä–≤–∏—Å–∞ MLflow

DAG_ID="mlsd_hw4" # <-- –ò–ó–ú–ï–ù–ï–ù–ò–ï: –û–±–Ω–æ–≤–ª–µ–Ω ID –¥–∞–≥–∞
API_USER="${AIRFLOW_API_USER}"
API_PASS="${AIRFLOW_API_PASS}"
API_EMAIL="${API_USER}@example.com"
AIRFLOW_API_URL="http://localhost:8080/api/v1"


# ---------- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–∂–∏–¥–∞–Ω–∏—è Healthcheck ----------

wait_healthy() {
    local service_name="$1"
    local timeout="${2:-120}"

    echo "==> –û–∂–∏–¥–∞–Ω–∏–µ healthcheck –¥–ª—è —Å–µ—Ä–≤–∏—Å–∞ '$service_name' (—Ç–∞–π–º–∞—É—Ç: ${timeout}s)..."

    local start_time=$(date +%s)
    while true; do
        local status=$(docker inspect --format '{{if .State.Health}}{{.State.Health.Status}}{{end}}' "hw4-${service_name}" 2>/dev/null || echo "not found")

        if [[ "$status" == "healthy" ]]; then
            echo "‚úÖ –°–µ—Ä–≤–∏—Å '$service_name' –≥–æ—Ç–æ–≤."
            return 0
        fi

        local current_time=$(date +%s)
        if (( current_time - start_time > timeout )); then
            echo "‚ùå –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è healthcheck –¥–ª—è —Å–µ—Ä–≤–∏—Å–∞ '$service_name'."
            echo "–ü–æ—Å–ª–µ–¥–Ω–∏–µ –ª–æ–≥–∏:"
            docker compose logs --tail=100 "$service_name"
            exit 1
        fi

        echo -n "."
        sleep 5
    done
}


# --- –û—Å–Ω–æ–≤–Ω–æ–π —Å—Ü–µ–Ω–∞—Ä–∏–π ---

echo "--- [–≠–¢–ê–ü 1/7] –°–±–æ—Ä–∫–∞ Docker-–æ–±—Ä–∞–∑–æ–≤ ---"
docker compose build

echo -e "\n--- [–≠–¢–ê–ü 2/7] –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ ---"
docker compose up -d

echo -e "\n--- [–≠–¢–ê–ü 3/7] –û–∂–∏–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–π –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–æ–≤ ---"
# –í–∞—à–∞ –ª–æ–≥–∏–∫–∞ —Å Postgres –±—ã–ª–∞ —Ö–æ—Ä–æ—à–µ–π, –Ω–æ `docker compose up -d` –∏ —Ç–∞–∫ —É—á—Ç–µ—Ç depends_on
wait_healthy "$POSTGRES_SERVICE_NAME" 60
wait_healthy "$MINIO_SERVICE_NAME" 60
wait_healthy "$REDIS_SERVICE_NAME" 60
wait_healthy "$SPARK_MASTER_SERVICE_NAME" 60
wait_healthy "$SPARK_WORKER_SERVICE_NAME" 60
wait_healthy "$MLFLOW_SERVICE_NAME" 120 # <-- –ò–ó–ú–ï–ù–ï–ù–ò–ï: –î–æ–±–∞–≤–ª–µ–Ω–æ –æ–∂–∏–¥–∞–Ω–∏–µ MLflow
wait_healthy "$AIRFLOW_SERVICE_NAME" 300


echo -e "\n--- [–≠–¢–ê–ü 4/7] –°–æ–∑–¥–∞–Ω–∏–µ/–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ Airflow ---"
# –í–∞—à–∞ —Ñ—É–Ω–∫—Ü–∏—è create_user_with_retry –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
create_user_with_retry() {
  EMAIL="${API_EMAIL}"
  max_attempts=7
  attempt=1
  sleep_between=5

  while [ $attempt -le $max_attempts ]; do
    echo "[$(date -Iseconds)] –ü–æ–ø—ã—Ç–∫–∞ $attempt/$max_attempts: —Å–æ–∑–¥–∞—ë–º/–æ–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è '$API_USER' (email: $EMAIL)..."
    out="$(docker compose exec --user airflow "$AIRFLOW_SERVICE_NAME" bash -lc "\
      airflow users create \
        --username '$API_USER' \
        --password '$API_PASS' \
        --firstname 'Admin' \
        --lastname 'User' \
        --role 'Admin' \
        --email '$EMAIL' 2>&1" || true)"
    echo "=== –í—ã–≤–æ–¥ —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ==="; echo "$out"; echo "=== –ö–æ–Ω–µ—Ü –≤—ã–≤–æ–¥–∞ ==="
    if echo "$out" | grep -i -E "created|already exist|already exists|already in the db" >/dev/null 2>&1; then
      echo "‚ÑπÔ∏è –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–æ–∑–¥–∞–Ω –∏–ª–∏ —É–∂–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª. –ü—Ä–æ–≤–µ—Ä—è–µ–º API..."
      http_code="$(docker compose exec --user airflow "$AIRFLOW_SERVICE_NAME" bash -lc "curl -s -o /dev/null -w '%{http_code}' -u '${API_USER}:${API_PASS}' 'http://localhost:8080/api/v1/dags/${DAG_ID}'" || echo "000")"
      if [ "$http_code" = "200" ]; then echo "‚úÖ API –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞."; return 0; fi
      if [ "$http_code" = "401" ]; then
        echo "‚ùó API –≤–µ—Ä–Ω—É–ª 401. –ü–æ–ø—Ä–æ–±—É–µ–º –æ–±–Ω–æ–≤–∏—Ç—å –ø–∞—Ä–æ–ª—å."
        pw_hash="$(docker compose exec --user airflow "$AIRFLOW_SERVICE_NAME" bash -lc "python -c 'from werkzeug.security import generate_password_hash; print(generate_password_hash(\"${API_PASS}\"))'" 2>/dev/null || true)"
        if [ -n "$pw_hash" ]; then
          docker compose exec postgres psql -U airflow -d airflow -c "UPDATE ab_user SET password = '$pw_hash' WHERE username = '${API_USER}';" >/dev/null 2>&1 || true
          http_code2="$(docker compose exec --user airflow "$AIRFLOW_SERVICE_NAME" bash -lc "curl -s -o /dev/null -w '%{http_code}' -u '${API_USER}:${API_PASS}' 'http://localhost:8080/api/v1/dags/${DAG_ID}'" || echo "000")"
          if [ "$http_code2" = "200" ]; then echo "‚úÖ –ü–∞—Ä–æ–ª—å –æ–±–Ω–æ–≤–ª—ë–Ω, –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞."; return 0; fi
        fi
      fi
    elif echo "$out" | grep -i "duplicate key value violates unique constraint \"ab_user_email_uq\"" >/dev/null 2>&1; then
        echo "‚ö†Ô∏è –ö–æ–Ω—Ñ–ª–∏–∫—Ç –ø–æ email. –ü—Ä–æ–±—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π email."
        EMAIL="${API_USER}@example.com"
        attempt=$((attempt+1)); sleep $sleep_between; continue
    fi
    echo "‚ùå –ü–æ–ø—ã—Ç–∫–∞ $attempt –Ω–µ —É–¥–∞–ª–∞—Å—å."; attempt=$((attempt+1)); sleep $sleep_between
  done
  echo "–û–®–ò–ë–ö–ê: –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å/–∏—Å–ø—Ä–∞–≤–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."; return 1
}
create_user_with_retry


# --- [–≠–¢–ê–ü 5/7] –ó–∞–ø—É—Å–∫ DAG —á–µ—Ä–µ–∑ REST API ---
# –í–∞—à –±–ª–æ–∫ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏ –æ–∂–∏–¥–∞–Ω–∏—è DAG –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
echo -e "\n--- [–≠–¢–ê–ü 5/7] –û–∂–∏–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ DAG —á–µ—Ä–µ–∑ REST API ---"
echo "–û–∂–∏–¥–∞–µ–º, –ø–æ–∫–∞ DAG '$DAG_ID' –Ω–µ –ø–æ—è–≤–∏—Ç—Å—è –≤ API..."
ATTEMPTS=30
for i in $(seq 1 $ATTEMPTS); do
    http_code=$(docker compose exec "$AIRFLOW_SERVICE_NAME" curl -s -o /dev/null -w "%{http_code}" -u "${API_USER}:${API_PASS}" "${AIRFLOW_API_URL}/dags/${DAG_ID}")
    if [ "$http_code" -eq 200 ]; then echo "‚úÖ DAG '$DAG_ID' –Ω–∞–π–¥–µ–Ω."; break; else echo "–û–∂–∏–¥–∞–µ–º DAG... ($i/$ATTEMPTS, http: $http_code)"; sleep 10; fi
    if [ $i -eq $ATTEMPTS ]; then echo "‚ùå DAG '$DAG_ID' –Ω–µ –ø–æ—è–≤–∏–ª—Å—è –≤ API."; exit 1; fi
done
echo "–í–∫–ª—é—á–∞–µ–º (unpause) DAG '$DAG_ID'..."
docker compose exec "$AIRFLOW_SERVICE_NAME" curl -X PATCH -u "${API_USER}:${API_PASS}" "${AIRFLOW_API_URL}/dags/${DAG_ID}" -H "Content-Type: application/json" -d '{"is_paused": false}'
RUN_ID="api_run_$(date +%Y-%m-%dT%H:%M:%S%z)"
echo "–ó–∞–ø—É—Å–∫–∞–µ–º DAG '$DAG_ID' —Å run_id = $RUN_ID..."
docker compose exec "$AIRFLOW_SERVICE_NAME" curl -X POST -u "${API_USER}:${API_PASS}" "${AIRFLOW_API_URL}/dags/${DAG_ID}/dagRuns" -H "Content-Type: application/json" -d "{\"dag_run_id\": \"$RUN_ID\"}"
echo "–û–∂–∏–¥–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è DAG'–∞..."
sleep 15
while true; do
    status=$(docker compose exec "$AIRFLOW_SERVICE_NAME" curl -s -u "${API_USER}:${API_PASS}" "${AIRFLOW_API_URL}/dags/${DAG_ID}/dagRuns/${RUN_ID}" | python3 -c "import sys, json; print(json.load(sys.stdin).get('state', 'unknown'))")
    if [[ "$status" == "success" ]]; then echo "‚úÖ DAG '$DAG_ID' —É—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω."; break;
    elif [[ "$status" == "failed" ]]; then echo "‚ùå DAG '$DAG_ID' –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π."; exit 1; fi
    printf "–°—Ç–∞—Ç—É—Å DAG'–∞: %s. –û–∂–∏–¥–∞–µ–º...\n" "$status"; sleep 15
done


# --- [–≠–¢–ê–ü 6/7] –ó–∞–ø—É—Å–∫ Model Serving –≤ MLflow --- # <-- –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ù–æ–≤—ã–π —ç—Ç–∞–ø
echo -e "\n--- [–≠–¢–ê–ü 6/7] –ó–∞–ø—É—Å–∫ Model Serving –≤ MLflow ---"
MODEL_NAME="logistic_regression_movielens" # –ò–º—è –º–æ–¥–µ–ª–∏, —É–∫–∞–∑–∞–Ω–Ω–æ–µ –≤ train_model.py
echo "–ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Ä–≤–µ—Ä –¥–ª—è –º–æ–¥–µ–ª–∏ '${MODEL_NAME}' –Ω–∞ –ø–æ—Ä—Ç—É 6000..."
docker compose exec -d "$MLFLOW_SERVICE_NAME" mlflow models serve \
    -m "models:/${MODEL_NAME}/latest" \
    -h 0.0.0.0 \
    -p 6000 \
    --no-conda

echo "–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ –º–æ–¥–µ–ª–∏ (–¥–æ 90 —Å–µ–∫—É–Ω–¥)..."
MODEL_SERVER_TIMEOUT=90
MODEL_SERVER_START=$(date +%s)
while true; do
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Ç–≤–µ—á–∞–µ—Ç –ª–∏ —Å–µ—Ä–≤–µ—Ä –º–æ–¥–µ–ª–∏
    if curl -s -o /dev/null -w "%{http_code}" http://localhost:6000/health 2>/dev/null | grep -qE "200|405"; then
        echo "‚úÖ –°–µ—Ä–≤–µ—Ä –º–æ–¥–µ–ª–∏ –≥–æ—Ç–æ–≤."
        break
    fi
    
    CURRENT_TIME=$(date +%s)
    ELAPSED=$((CURRENT_TIME - MODEL_SERVER_START))
    if [ $ELAPSED -ge $MODEL_SERVER_TIMEOUT ]; then
        echo "‚ö†Ô∏è –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è —Å–µ—Ä–≤–µ—Ä–∞ –º–æ–¥–µ–ª–∏. –ü—Ä–æ–±—É–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –Ω–∞–ø—Ä—è–º—É—é..."
        break
    fi
    
    echo -n "."
    sleep 5
done


# --- [–≠–¢–ê–ü 7/7] –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ --- # <-- –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ù–æ–≤—ã–π —ç—Ç–∞–ø
echo -e "\n--- [–≠–¢–ê–ü 7/7] –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ---"
echo "–ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è user_id=17 –≤ Redis..."
result=$(docker compose exec "$REDIS_SERVICE_NAME" redis-cli GET 17)
if [ -z "$result" ]; then
    echo "‚ùå –ö–ª—é—á –¥–ª—è user_id=17 –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ Redis."; exit 1
else
    echo "‚úÖ –ö–ª—é—á –¥–ª—è user_id=17 –Ω–∞–π–¥–µ–Ω!"
fi

echo "–§–æ—Ä–º–∏—Ä—É–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏..."
# –ë–µ—Ä–µ–º –∏–∑ Redis —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–∏
AVG_RATING=$(echo $result | python3 -c "import sys, json; print(json.load(sys.stdin)['avg_rating'])")
NUM_MOVIES=$(echo $result | python3 -c "import sys, json; print(json.load(sys.stdin)['num_movies'])")

# –§–æ—Ä–º–∏—Ä—É–µ–º JSON-–∑–∞–ø—Ä–æ—Å –≤ —Ñ–æ—Ä–º–∞—Ç–µ, –∫–æ—Ç–æ—Ä—ã–π –æ–∂–∏–¥–∞–µ—Ç MLflow
JSON_PAYLOAD="{\"dataframe_split\": {\"columns\": [\"avg_rating\", \"num_movies\"], \"data\":[[$AVG_RATING, $NUM_MOVIES]]}}"

# –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å —Å –ø–æ–º–æ—â—å—é curl
prediction_response=$(curl -s -X POST -H "Content-Type:application/json" --data "$JSON_PAYLOAD" http://localhost:6000/invocations)
prediction=$(echo $prediction_response | python3 -c "import sys, json; print(json.load(sys.stdin)['predictions'][0])")

if [[ "$prediction" == "0" || "$prediction" == "1" ]]; then
    echo "‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –≤–µ—Ä–Ω—É–ª–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: $prediction"
else
    echo "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ç –º–æ–¥–µ–ª–∏. –û—Ç–≤–µ—Ç:"
    echo "$prediction_response"
    exit 1
fi

echo -e "\n\nüéâüéâüéâ –ü–†–û–ï–ö–¢ –£–°–ü–ï–®–ù–û –ó–ê–ü–£–©–ï–ù –ò –ü–†–û–í–ï–†–ï–ù! üéâüéâüéâ"
echo
echo "–¢–æ—á–∫–∏ –¥–æ—Å—Ç—É–ø–∞ –∫ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞–º:"
echo " - MinIO Console:    http://localhost:9001 (${MINIO_ROOT_USER}/${MINIO_ROOT_PASSWORD})"
echo " - Spark Master UI:  http://localhost:8080"
echo " - Spark Worker UI:  http://localhost:8081"
echo " - Airflow UI:       http://localhost:8088 (${API_USER}/${API_PASS})"
echo " - MLflow UI:        http://localhost:5000"
echo " - Model Endpoint:   http://localhost:6000/invocations"
echo " - Redis:            localhost:6379 (no auth)"



