#!/usr/bin/env bash
set -euo pipefail

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏–∑ .env ---
if [ -f .env ]; then
  set -a
  source .env
  set +a
fi

# --- –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (–∏–∑ .env) ---
export MINIO_ROOT_USER
export MINIO_ROOT_PASSWORD
export AIRFLOW_UID=$(id -u)
export IMAGE_TAG
echo "INFO: IMAGE_TAG = ${IMAGE_TAG}"

# --- –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ ---
MINIO_SERVICE_NAME="minio"
REDIS_SERVICE_NAME="redis"
SPARK_MASTER_SERVICE_NAME="spark-master"
SPARK_WORKER_SERVICE_NAME="spark-worker-1"
AIRFLOW_SERVICE_NAME="airflow"
POSTGRES_SERVICE_NAME="postgres"
MLFLOW_SERVICE_NAME="mlflow"
KAFKA_SERVICE_NAME="kafka"
INFERENCE_SERVICE_NAME="inference"

DAG_ID="mlops_platform"
API_USER="${AIRFLOW_API_USER}"
API_PASS="${AIRFLOW_API_PASS}"
API_EMAIL="${API_USER}@example.com"
AIRFLOW_API_URL="http://localhost:8080/api/v1"


# ---------- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–∂–∏–¥–∞–Ω–∏—è Healthcheck ----------

wait_healthy() {
    local service_name="$1"
    local timeout="${2:-120}"

    echo "==> –û–∂–∏–¥–∞–Ω–∏–µ healthcheck –¥–ª—è —Å–µ—Ä–≤–∏—Å–∞ '$service_name' (—Ç–∞–π–º–∞—É—Ç: ${timeout}s)..."

    local start_time=$(date +%s)
    while true; do
        local status=$(docker inspect --format '{{if .State.Health}}{{.State.Health.Status}}{{end}}' "mlops-${service_name}" 2>/dev/null || echo "not found")

        if [[ "$status" == "healthy" ]]; then
            echo "‚úÖ –°–µ—Ä–≤–∏—Å '$service_name' –≥–æ—Ç–æ–≤."
            return 0
        fi

        local current_time=$(date +%s)
        if (( current_time - start_time > timeout )); then
            echo "‚ùå –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è healthcheck –¥–ª—è —Å–µ—Ä–≤–∏—Å–∞ '$service_name'."
            echo "–ü–æ—Å–ª–µ–¥–Ω–∏–µ –ª–æ–≥–∏:"
            docker compose logs --tail=100 "$service_name"
            exit 1
        fi

        echo -n "."
        sleep 5
    done
}


# --- –û—Å–Ω–æ–≤–Ω–æ–π —Å—Ü–µ–Ω–∞—Ä–∏–π ---

echo "--- [–≠–¢–ê–ü 0/7] –û—á–∏—Å—Ç–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è ---"
echo "–£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã, volumes –∏ –ª–æ–∫–∞–ª—å–Ω—ã–µ –æ–±—Ä–∞–∑—ã..."
docker compose down -v --rmi local --remove-orphans || true

echo "--- [–≠–¢–ê–ü 1/7] –°–±–æ—Ä–∫–∞ Docker-–æ–±—Ä–∞–∑–æ–≤ ---"
docker compose build

echo -e "\n--- [–≠–¢–ê–ü 2/7] –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ ---"
docker compose up -d

echo -e "\n--- [–≠–¢–ê–ü 3/7] –û–∂–∏–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–π –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–æ–≤ ---"
wait_healthy "$POSTGRES_SERVICE_NAME" 60
wait_healthy "$MINIO_SERVICE_NAME" 60
wait_healthy "$REDIS_SERVICE_NAME" 60
wait_healthy "$SPARK_MASTER_SERVICE_NAME" 60
wait_healthy "$SPARK_WORKER_SERVICE_NAME" 60
wait_healthy "$KAFKA_SERVICE_NAME" 60
wait_healthy "$MLFLOW_SERVICE_NAME" 120

wait_healthy "$AIRFLOW_SERVICE_NAME" 300


echo -e "\n--- [–≠–¢–ê–ü 4/7] –°–æ–∑–¥–∞–Ω–∏–µ/–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ Airflow ---"
create_user_with_retry() {
  EMAIL="${API_EMAIL}"
  max_attempts=7
  attempt=1
  sleep_between=5

  while [ $attempt -le $max_attempts ]; do
    echo "[$(date -Iseconds)] –ü–æ–ø—ã—Ç–∫–∞ $attempt/$max_attempts: —Å–æ–∑–¥–∞—ë–º/–æ–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è '$API_USER' (email: $EMAIL)..."
    out="$(docker compose exec --user airflow "$AIRFLOW_SERVICE_NAME" bash -lc "\
      airflow users create \
        --username '$API_USER' \
        --password '$API_PASS' \
        --firstname 'Admin' \
        --lastname 'User' \
        --role 'Admin' \
        --email '$EMAIL' 2>&1" || true)"
    echo "=== –í—ã–≤–æ–¥ —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ==="; echo "$out"; echo "=== –ö–æ–Ω–µ—Ü –≤—ã–≤–æ–¥–∞ ==="
    if echo "$out" | grep -i -E "created|already exist|already exists|already in the db" >/dev/null 2>&1; then
      echo "‚ÑπÔ∏è –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–æ–∑–¥–∞–Ω –∏–ª–∏ —É–∂–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª. –ü—Ä–æ–≤–µ—Ä—è–µ–º API..."
      http_code="$(docker compose exec --user airflow "$AIRFLOW_SERVICE_NAME" bash -lc "curl -s -o /dev/null -w '%{http_code}' -u '${API_USER}:${API_PASS}' 'http://localhost:8080/api/v1/dags/${DAG_ID}'" || echo "000")"
      if [ "$http_code" = "200" ]; then echo "‚úÖ API –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞."; return 0; fi
      if [ "$http_code" = "401" ]; then
        echo "‚ùó API –≤–µ—Ä–Ω—É–ª 401. –ü–æ–ø—Ä–æ–±—É–µ–º –æ–±–Ω–æ–≤–∏—Ç—å –ø–∞—Ä–æ–ª—å."
        pw_hash="$(docker compose exec --user airflow "$AIRFLOW_SERVICE_NAME" bash -lc "python -c 'from werkzeug.security import generate_password_hash; print(generate_password_hash(\"${API_PASS}\"))'" 2>/dev/null || true)"
        if [ -n "$pw_hash" ]; then
          docker compose exec postgres psql -U airflow -d airflow -c "UPDATE ab_user SET password = '$pw_hash' WHERE username = '${API_USER}';" >/dev/null 2>&1 || true
          http_code2="$(docker compose exec --user airflow "$AIRFLOW_SERVICE_NAME" bash -lc "curl -s -o /dev/null -w '%{http_code}' -u '${API_USER}:${API_PASS}' 'http://localhost:8080/api/v1/dags/${DAG_ID}'" || echo "000")"
          if [ "$http_code2" = "200" ]; then echo "‚úÖ –ü–∞—Ä–æ–ª—å –æ–±–Ω–æ–≤–ª—ë–Ω, –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞."; return 0; fi
        fi
      fi
    elif echo "$out" | grep -i "duplicate key value violates unique constraint \"ab_user_email_uq\"" >/dev/null 2>&1; then
        echo "‚ö†Ô∏è –ö–æ–Ω—Ñ–ª–∏–∫—Ç –ø–æ email. –ü—Ä–æ–±—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π email."
        EMAIL="${API_USER}@example.com"
        attempt=$((attempt+1)); sleep $sleep_between; continue
    fi
    echo "‚ùå –ü–æ–ø—ã—Ç–∫–∞ $attempt –Ω–µ —É–¥–∞–ª–∞—Å—å."; attempt=$((attempt+1)); sleep $sleep_between
  done
  echo "–û–®–ò–ë–ö–ê: –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å/–∏—Å–ø—Ä–∞–≤–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."; return 1
}
create_user_with_retry


echo -e "\n--- [–≠–¢–ê–ü 5/7] –û–∂–∏–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ DAG —á–µ—Ä–µ–∑ REST API ---"
echo "–û–∂–∏–¥–∞–µ–º, –ø–æ–∫–∞ DAG '$DAG_ID' –Ω–µ –ø–æ—è–≤–∏—Ç—Å—è –≤ API..."
ATTEMPTS=30
for i in $(seq 1 $ATTEMPTS); do
    http_code=$(docker compose exec "$AIRFLOW_SERVICE_NAME" curl -s -o /dev/null -w "%{http_code}" -u "${API_USER}:${API_PASS}" "${AIRFLOW_API_URL}/dags/${DAG_ID}")
    if [ "$http_code" -eq 200 ]; then echo "‚úÖ DAG '$DAG_ID' –Ω–∞–π–¥–µ–Ω."; break; else echo "–û–∂–∏–¥–∞–µ–º DAG... ($i/$ATTEMPTS, http: $http_code)"; sleep 10; fi
    if [ $i -eq $ATTEMPTS ]; then echo "‚ùå DAG '$DAG_ID' –Ω–µ –ø–æ—è–≤–∏–ª—Å—è –≤ API."; exit 1; fi
done
echo "–í–∫–ª—é—á–∞–µ–º (unpause) DAG '$DAG_ID'..."
docker compose exec "$AIRFLOW_SERVICE_NAME" curl -X PATCH -u "${API_USER}:${API_PASS}" "${AIRFLOW_API_URL}/dags/${DAG_ID}" -H "Content-Type: application/json" -d '{"is_paused": false}'
RUN_ID="api_run_$(date +%Y-%m-%dT%H:%M:%S%z)"
echo "–ó–∞–ø—É—Å–∫–∞–µ–º DAG '$DAG_ID' —Å run_id = $RUN_ID..."
docker compose exec "$AIRFLOW_SERVICE_NAME" curl -X POST -u "${API_USER}:${API_PASS}" "${AIRFLOW_API_URL}/dags/${DAG_ID}/dagRuns" -H "Content-Type: application/json" -d "{\"dag_run_id\": \"$RUN_ID\"}"
echo "–û–∂–∏–¥–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è DAG'–∞..."
sleep 15
while true; do
    status=$(docker compose exec "$AIRFLOW_SERVICE_NAME" curl -s -u "${API_USER}:${API_PASS}" "${AIRFLOW_API_URL}/dags/${DAG_ID}/dagRuns/${RUN_ID}" | python3 -c "import sys, json; print(json.load(sys.stdin).get('state', 'unknown'))")
    if [[ "$status" == "success" ]]; then echo "‚úÖ DAG '$DAG_ID' —É—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω."; break;
    elif [[ "$status" == "failed" ]]; then echo "‚ùå DAG '$DAG_ID' –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π."; exit 1; fi
    printf "–°—Ç–∞—Ç—É—Å DAG'–∞: %s. –û–∂–∏–¥–∞–µ–º...\n" "$status"; sleep 15
done


echo -e "\n--- [–≠–¢–ê–ü 6/7] –ó–∞–ø—É—Å–∫ Model Serving –≤ MLflow ---"
MODEL_NAME="logistic_regression_movielens"
echo "–ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Ä–≤–µ—Ä –¥–ª—è –º–æ–¥–µ–ª–∏ '${MODEL_NAME}' –Ω–∞ –ø–æ—Ä—Ç—É 6000..."
docker compose exec -d "$MLFLOW_SERVICE_NAME" mlflow models serve \
    -m "models:/${MODEL_NAME}/latest" \
    -h 0.0.0.0 \
    -p 6000 \
    --no-conda

echo "–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ –º–æ–¥–µ–ª–∏ (–¥–æ 90 —Å–µ–∫—É–Ω–¥)..."
MODEL_SERVER_TIMEOUT=90
MODEL_SERVER_START=$(date +%s)
while true; do
    if curl -s -o /dev/null -w "%{http_code}" http://localhost:6000/health 2>/dev/null | grep -qE "200|405"; then
        echo "‚úÖ –°–µ—Ä–≤–µ—Ä –º–æ–¥–µ–ª–∏ –≥–æ—Ç–æ–≤."
        break
    fi
    
    CURRENT_TIME=$(date +%s)
    ELAPSED=$((CURRENT_TIME - MODEL_SERVER_START))
    if [ $ELAPSED -ge $MODEL_SERVER_TIMEOUT ]; then
        echo "‚ö†Ô∏è –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è —Å–µ—Ä–≤–µ—Ä–∞ –º–æ–¥–µ–ª–∏. –ü—Ä–æ–±—É–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –Ω–∞–ø—Ä—è–º—É—é..."
        break
    fi
    
    echo -n "."
    sleep 5
done


echo -e "\n--- [–≠–¢–ê–ü 7/7] –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ ---"
echo "‚úÖ –ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞, –ø–∞–π–ø–ª–∞–π–Ω –æ–±—É—á–µ–Ω–∏—è –∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å-—Å–µ—Ä–≤–∏—Å –∑–∞–ø—É—â–µ–Ω—ã."
echo "–î–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python3 verify_streaming.py"

echo -e "\n\nüéâüéâüéâ –ü–†–û–ï–ö–¢ –£–°–ü–ï–®–ù–û –ó–ê–ü–£–©–ï–ù! üéâüéâüéâ"
echo
echo "–¢–æ—á–∫–∏ –¥–æ—Å—Ç—É–ø–∞ –∫ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞–º:"
echo " - MinIO Console:    http://localhost:9001 (${MINIO_ROOT_USER}/${MINIO_ROOT_PASSWORD})"
echo " - Spark Master UI:  http://localhost:8080"
echo " - Spark Worker UI:  http://localhost:8081"
echo " - Airflow UI:       http://localhost:8088 (${API_USER}/${API_PASS})"
echo " - MLflow UI:        http://localhost:5000"
echo " - Model Endpoint:   http://localhost:6000/invocations"
echo " - Kafka UI:         http://localhost:8090"
echo " - Kafka:            localhost:29092 (external), kafka:9092 (internal)"
echo " - Redis:            localhost:6379 (no auth)"
