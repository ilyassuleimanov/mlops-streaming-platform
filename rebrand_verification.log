INFO: IMAGE_TAG = suleimanov_ilias
--- [–≠–¢–ê–ü 0/7] –û—á–∏—Å—Ç–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è ---
–£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã, volumes –∏ –ª–æ–∫–∞–ª—å–Ω—ã–µ –æ–±—Ä–∞–∑—ã...
 Container hw4-airflow  Stopping
 Container hw4-inference  Stopping
 Container hw4-kafka-ui  Stopping
 Container hw4-spark-worker-1  Stopping
 Container hw4-airflow  Stopped
 Container hw4-airflow  Removing
 Container hw4-spark-worker-1  Stopped
 Container hw4-spark-worker-1  Removing
 Container hw4-airflow  Removed
 Container hw4-postgres  Stopping
 Container hw4-spark-worker-1  Removed
 Container hw4-spark-master  Stopping
 Container hw4-postgres  Stopped
 Container hw4-postgres  Removing
 Container hw4-postgres  Removed
 Container hw4-spark-master  Stopped
 Container hw4-spark-master  Removing
 Container hw4-spark-master  Removed
 Container hw4-kafka-ui  Stopped
 Container hw4-kafka-ui  Removing
 Container hw4-kafka-ui  Removed
 Container hw4-inference  Stopped
 Container hw4-inference  Removing
 Container hw4-inference  Removed
 Container hw4-mlflow  Stopping
 Container hw4-redis  Stopping
 Container hw4-kafka  Stopping
 Container hw4-redis  Stopped
 Container hw4-redis  Removing
 Container hw4-redis  Removed
 Container hw4-kafka  Stopped
 Container hw4-kafka  Removing
 Container hw4-kafka  Removed
 Container hw4-mlflow  Stopped
 Container hw4-mlflow  Removing
 Container hw4-mlflow  Removed
 Container hw4-minio  Stopping
 Container hw4-minio  Stopped
 Container hw4-minio  Removing
 Container hw4-minio  Removed
 Image hw4-mlflow:latest  Removing
 Image mlsd-airflow:suleimanov_ilias  Removing
 Image mlsd-spark-master:suleimanov_ilias  Removing
 Image hw4-inference:latest  Removing
 Image mlsd-spark-worker-1:suleimanov_ilias  Removing
 Volume hw4_postgres_db  Removing
 Network hw4_mlsd-network  Removing
 Image mlsd-spark-worker-1:suleimanov_ilias  Removed
 Volume hw4_postgres_db  Removed
 Network hw4_mlsd-network  Removed
 Image hw4-inference:latest  Removed
 Image mlsd-airflow:suleimanov_ilias  Removed
 Image hw4-mlflow:latest  Removed
 Image mlsd-spark-master:suleimanov_ilias  Removed
--- [–≠–¢–ê–ü 1/7] –°–±–æ—Ä–∫–∞ Docker-–æ–±—Ä–∞–∑–æ–≤ ---
#1 [internal] load local bake definitions
#1 reading from stdin 2.36kB done
#1 DONE 0.0s

#2 [mlflow internal] load build definition from Dockerfile
#2 transferring dockerfile: 457B done
#2 DONE 0.0s

#3 [spark-worker-1 internal] load build definition from Dockerfile
#3 transferring dockerfile: 2.12kB done
#3 DONE 0.0s

#4 [airflow internal] load build definition from Dockerfile
#4 transferring dockerfile: 2.40kB done
#4 DONE 0.0s

#5 [inference internal] load build definition from Dockerfile
#5 transferring dockerfile: 426B 0.0s done
#5 DONE 0.0s

#6 [spark-worker-1 internal] load metadata for docker.io/apache/spark-py:v3.4.0
#6 ...

#7 [auth] apache/spark-py:pull token for registry-1.docker.io
#7 DONE 0.0s

#8 [auth] apache/airflow:pull token for registry-1.docker.io
#8 DONE 0.0s

#9 [auth] library/python:pull token for registry-1.docker.io
#9 DONE 0.0s

#10 [inference internal] load metadata for docker.io/library/python:3.10-slim
#10 ...

#11 [mlflow internal] load metadata for docker.io/library/python:3.9-slim
#11 DONE 1.7s

#12 [airflow internal] load metadata for docker.io/apache/airflow:2.8.1-python3.10
#12 DONE 1.7s

#10 [inference internal] load metadata for docker.io/library/python:3.10-slim
#10 DONE 1.8s

#13 [spark-master internal] load .dockerignore
#13 transferring context: 2B done
#13 DONE 0.0s

#14 [mlflow internal] load .dockerignore
#14 transferring context: 2B done
#14 DONE 0.0s

#15 [inference internal] load .dockerignore
#15 transferring context: 2B done
#15 DONE 0.0s

#16 [mlflow internal] load build context
#16 transferring context: 71B done
#16 DONE 0.0s

#17 [inference internal] load build context
#17 transferring context: 74B done
#17 DONE 0.0s

#6 [spark-master internal] load metadata for docker.io/apache/spark-py:v3.4.0
#6 DONE 1.8s

#18 [spark-master internal] load build context
#18 transferring context: 510B done
#18 DONE 0.0s

#19 [inference 1/6] FROM docker.io/library/python:3.10-slim@sha256:f5d029fe39146b08200bcc73595795ac19b85997ad0e5001a02c7c32e8769efa
#19 resolve docker.io/library/python:3.10-slim@sha256:f5d029fe39146b08200bcc73595795ac19b85997ad0e5001a02c7c32e8769efa 0.0s done
#19 DONE 0.0s

#20 [mlflow 1/6] FROM docker.io/library/python:3.9-slim@sha256:2d97f6910b16bd338d3060f261f53f144965f755599aab1acda1e13cf1731b1b
#20 resolve docker.io/library/python:3.9-slim@sha256:2d97f6910b16bd338d3060f261f53f144965f755599aab1acda1e13cf1731b1b 0.0s done
#20 DONE 0.0s

#21 [airflow  1/10] FROM docker.io/apache/airflow:2.8.1-python3.10@sha256:9e6fba276a0bdb6a13def5320b960a94c1ab074420b715828925bfdb2ecbebc5
#21 resolve docker.io/apache/airflow:2.8.1-python3.10@sha256:9e6fba276a0bdb6a13def5320b960a94c1ab074420b715828925bfdb2ecbebc5 0.0s done
#21 DONE 0.0s

#22 [inference 5/6] RUN pip install --no-cache-dir -r requirements.txt
#22 CACHED

#23 [inference 2/6] WORKDIR /app
#23 CACHED

#24 [inference 4/6] COPY requirements.txt .
#24 CACHED

#25 [inference 3/6] RUN apt-get update && apt-get install -y --no-install-recommends     build-essential     && rm -rf /var/lib/apt/lists/*
#25 CACHED

#26 [mlflow 4/6] COPY requirements.txt .
#26 CACHED

#27 [mlflow 2/6] RUN apt-get update && apt-get install -y curl && rm -rf /var/lib/apt/lists/*
#27 CACHED

#28 [mlflow 3/6] WORKDIR /mlflow_app
#28 CACHED

#29 [mlflow 5/6] RUN pip install --no-cache-dir -r requirements.txt
#29 CACHED

#30 [mlflow 6/6] COPY train_model.py .
#30 CACHED

#31 [inference 6/6] COPY queue_consumer.py .
#31 CACHED

#32 [mlflow] exporting to image
#32 exporting layers
#32 ...

#33 [spark-master 1/5] FROM docker.io/apache/spark-py:v3.4.0@sha256:5f6a8d82dd2667cedcdeb10d3c899ce2b91bc4e1c1bfc0abbc903829291ced6b
#33 resolve docker.io/apache/spark-py:v3.4.0@sha256:5f6a8d82dd2667cedcdeb10d3c899ce2b91bc4e1c1bfc0abbc903829291ced6b 0.0s done
#33 DONE 0.0s

#34 [spark-master 4/5] RUN apt-get update && apt-get install -y wget &&     wget https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar -P /opt/spark/jars/ &&     wget https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.262/aws-java-sdk-bundle-1.12.262.jar -P /opt/spark/jars/ &&     apt-get remove -y wget && apt-get autoremove -y && rm -rf /var/lib/apt/lists/*
#34 CACHED

#35 [spark-master 3/5] RUN pip install --no-cache-dir -r requirements.txt
#35 CACHED

#36 [spark-master 2/5] COPY spark/requirements.txt .
#36 CACHED

#37 [airflow internal] load build context
#37 transferring context: 8.64kB done
#37 DONE 0.0s

#38 [spark-worker-1 5/5] COPY spark-jobs /opt/spark/jobs
#38 CACHED

#39 [airflow  4/10] RUN set -eux;     cd /tmp;     SPARK_TGZ="spark-3.4.0-bin-hadoop3.tgz";     SPARK_URL="https://archive.apache.org/dist/spark/spark-3.4.0/${SPARK_TGZ}";     wget -q "$SPARK_URL";     tar -xzf "$SPARK_TGZ" -C /opt;     mv /opt/spark-3.4.0-bin-hadoop3 /opt/spark;     rm -f "$SPARK_TGZ";
#39 CACHED

#40 [airflow  5/10] RUN set -eux;     cd /opt/spark/jars;     wget -q https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar;     wget -q https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.262/aws-java-sdk-bundle-1.12.262.jar
#40 CACHED

#41 [airflow  2/10] RUN apt-get update && apt-get install -y     curl     unzip     default-jre     build-essential     python3-dev     gettext-base     wget     postgresql-client     libpq-dev     && apt-get clean && rm -rf /var/lib/apt/lists/*
#41 CACHED

#42 [airflow  3/10] RUN curl -sSLo /usr/local/bin/mc https://dl.min.io/client/mc/release/linux-arm64/mc &&     chmod +x /usr/local/bin/mc
#42 CACHED

#43 [airflow  6/10] COPY airflow/requirements.txt .
#43 CACHED

#44 [airflow  7/10] RUN pip install -r requirements.txt --constraint "https://raw.githubusercontent.com/apache/airflow/constraints-2.8.1/constraints-3.10.txt"
#44 CACHED

#45 [airflow  8/10] COPY airflow/dags /opt/airflow/dags
#45 DONE 0.1s

#32 [mlflow] exporting to image
#32 exporting layers done
#32 exporting manifest sha256:2a659a79d401177cfbddccf0ac8f44f9285664961ce62d7477ea66400bd12e51 0.0s done
#32 exporting config sha256:fdfa912ec7090a89f2457da0c3664016d9ebdc1280df30709aab3a9a85a5eb5c 0.0s done
#32 exporting attestation manifest sha256:33f4d5c935701f08f6197b0375cd224cc55d8f6eb699e419a0bdd800c0f4def2 0.0s done
#32 exporting manifest list sha256:726e3212770851dee1fb1fbbdbc0e1e389d7d7c2c86bc1cc5c115799968097ec
#32 ...

#46 [airflow  9/10] COPY spark-jobs /opt/airflow/spark-jobs
#46 DONE 0.1s

#32 [mlflow] exporting to image
#32 exporting manifest list sha256:726e3212770851dee1fb1fbbdbc0e1e389d7d7c2c86bc1cc5c115799968097ec 0.0s done
#32 naming to docker.io/library/hw4-mlflow:latest done
#32 unpacking to docker.io/library/hw4-mlflow:latest
#32 ...

#47 [airflow 10/10] RUN mkdir -p /opt/airflow/logs /opt/airflow/plugins &&     chown -R 50000:0 /opt/airflow/dags /opt/airflow/spark-jobs /opt/airflow/logs /opt/airflow/plugins &&     chmod -R 775 /opt/airflow/dags /opt/airflow/spark-jobs /opt/airflow/logs /opt/airflow/plugins
#47 DONE 0.9s

#48 [airflow] exporting to image
#48 exporting layers 0.1s done
#48 exporting manifest sha256:2fc581fd185e4717e4e20e06a11c89388722ab30242cd6a30ef5e00b4e82054e
#48 exporting manifest sha256:2fc581fd185e4717e4e20e06a11c89388722ab30242cd6a30ef5e00b4e82054e 0.0s done
#48 exporting config sha256:65ff77042ed14930caf079d7acd297e09027b32db8f6ea396093ba55a9ad23d2 0.0s done
#48 exporting attestation manifest sha256:8599c3c394b65878cd06893b943c06bba0a484ebd97418d495f889ca2bd23197 0.0s done
#48 exporting manifest list sha256:d5f5ab88250f7a44252ac2df1bdae62d2db52b7e27f2598463bf7dda686b3d7d done
#48 naming to docker.io/library/mlsd-airflow:suleimanov_ilias done
#48 unpacking to docker.io/library/mlsd-airflow:suleimanov_ilias
#48 ...

#49 [spark-worker-1] exporting to image
#49 exporting layers 0.0s done
#49 exporting manifest sha256:970e300636c54b8652a9bcb99e171467976eb1e878dd64db54546d1851d00c67 0.0s done
#49 exporting config sha256:a4a149fbc12ac5b7e84e949a5c60e2ef0b5fc3a8371722d2e6cc85c5a5df8ef5 done
#49 exporting attestation manifest sha256:dd6ef3130e5084cbd3d4c0a27b6e8e55f3a26851f3af15cf9e39e005dabaa517 0.1s done
#49 exporting manifest list sha256:27a915f934439a0b67e8611b7fa48c1e134ccb21d93170aadfeeacfcb3261ca1 0.0s done
#49 naming to docker.io/library/mlsd-spark-worker-1:suleimanov_ilias done
#49 unpacking to docker.io/library/mlsd-spark-worker-1:suleimanov_ilias 9.0s done
#49 DONE 9.3s

#50 [spark-master] exporting to image
#50 exporting layers 0.0s done
#50 exporting manifest sha256:949762075938fdeefbbe4490517dca7dcb49f156a9b6e08a18edfb3396b79ae3 0.0s done
#50 exporting config sha256:1b1003300d29e12cc69f65d8bb54a53996403a101b6709479a46101a9416faff done
#50 exporting attestation manifest sha256:41574f81952e4ed261913eee7fb619ea09231c1423a6b40c403497ea792ed69e 0.1s done
#50 exporting manifest list sha256:e450fad15028a91e02078bee46060fc8500656399caea7bbb8bcc2010cac798a 0.0s done
#50 naming to docker.io/library/mlsd-spark-master:suleimanov_ilias done
#50 unpacking to docker.io/library/mlsd-spark-master:suleimanov_ilias 9.0s done
#50 DONE 9.3s

#51 [inference] exporting to image
#51 exporting layers done
#51 exporting manifest sha256:6564750904d65c6f6715eb372a9032f080e7f9ab59ac88db28c5f9a3e3d67618 0.0s done
#51 exporting config sha256:f189a343b74debe07f4fc545b85eaca35652bdeb1607dfa34a39e043cd7915e0 0.0s done
#51 exporting attestation manifest sha256:834fe25364302c1e2ace774469d72d2d295a3cdadb71a328aee3692fd4c62bf9 0.0s done
#51 exporting manifest list sha256:bc7dd62a39a5b4c695d92a5dcd38869f23a079609c5b405c9f2cc62d74fe4d33 0.0s done
#51 naming to docker.io/library/hw4-inference:latest 0.0s done
#51 unpacking to docker.io/library/hw4-inference:latest
#51 ...

#52 [spark-worker-1] resolving provenance for metadata file
#52 DONE 0.0s

#53 [spark-master] resolving provenance for metadata file
#53 DONE 0.0s

#48 [airflow] exporting to image
#48 ...

#32 [mlflow] exporting to image
#32 unpacking to docker.io/library/hw4-mlflow:latest 11.2s done
#32 DONE 11.4s

#54 [mlflow] resolving provenance for metadata file
#54 DONE 0.0s

#51 [inference] exporting to image
#51 unpacking to docker.io/library/hw4-inference:latest 13.1s done
#51 DONE 13.3s

#55 [inference] resolving provenance for metadata file
#55 DONE 0.0s

#48 [airflow] exporting to image
#48 unpacking to docker.io/library/mlsd-airflow:suleimanov_ilias 23.5s done
#48 DONE 23.8s

#56 [airflow] resolving provenance for metadata file
#56 DONE 0.0s
 hw4-inference  Built
 mlsd-airflow:suleimanov_ilias  Built
 hw4-mlflow  Built
 mlsd-spark-master:suleimanov_ilias  Built
 mlsd-spark-worker-1:suleimanov_ilias  Built

--- [–≠–¢–ê–ü 2/7] –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ ---
 Network hw4_mlsd-network  Creating
 Network hw4_mlsd-network  Created
 Volume hw4_postgres_db  Creating
 Volume hw4_postgres_db  Created
 Container mlops-kafka  Creating
 Container mlops-minio  Creating
 Container mlops-redis  Creating
 Container mlops-spark-master  Creating
 Container mlops-postgres  Creating
 Container mlops-minio  Created
 Container mlops-mlflow  Creating
 Container mlops-spark-master  Created
 Container mlops-spark-worker-1  Creating
 Container mlops-postgres  Created
 Container mlops-kafka  Created
 Container mlops-kafka-ui  Creating
 Container mlops-redis  Created
 Container mlops-airflow  Creating
 Container mlops-mlflow  Created
 Container mlops-inference  Creating
 Container mlops-kafka-ui  Created
 Container mlops-spark-worker-1  Created
 Container mlops-airflow  Created
 Container mlops-inference  Created
 Container mlops-spark-master  Starting
 Container mlops-postgres  Starting
 Container mlops-redis  Starting
 Container mlops-kafka  Starting
 Container mlops-minio  Starting
 Container mlops-postgres  Started
 Container mlops-redis  Started
 Container mlops-kafka  Started
 Container mlops-kafka  Waiting
 Container mlops-spark-master  Started
 Container mlops-spark-worker-1  Starting
 Container mlops-minio  Started
 Container mlops-mlflow  Starting
 Container mlops-spark-master  Waiting
 Container mlops-minio  Waiting
 Container mlops-redis  Waiting
 Container mlops-postgres  Waiting
 Container mlops-spark-worker-1  Started
 Container mlops-mlflow  Started
 Container mlops-kafka  Waiting
 Container mlops-redis  Waiting
 Container mlops-mlflow  Waiting
 Container mlops-redis  Healthy
 Container mlops-redis  Healthy
 Container mlops-postgres  Healthy
 Container mlops-spark-master  Healthy
 Container mlops-minio  Healthy
 Container mlops-airflow  Starting
 Container mlops-mlflow  Healthy
 Container mlops-airflow  Started
 Container mlops-kafka  Healthy
 Container mlops-inference  Starting
 Container mlops-kafka  Healthy
 Container mlops-kafka-ui  Starting
 Container mlops-inference  Started
 Container mlops-kafka-ui  Started

--- [–≠–¢–ê–ü 3/7] –û–∂–∏–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–π –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–æ–≤ ---
==> –û–∂–∏–¥–∞–Ω–∏–µ healthcheck –¥–ª—è —Å–µ—Ä–≤–∏—Å–∞ 'postgres' (—Ç–∞–π–º–∞—É—Ç: 60s)...
‚úÖ –°–µ—Ä–≤–∏—Å 'postgres' –≥–æ—Ç–æ–≤.
==> –û–∂–∏–¥–∞–Ω–∏–µ healthcheck –¥–ª—è —Å–µ—Ä–≤–∏—Å–∞ 'minio' (—Ç–∞–π–º–∞—É—Ç: 60s)...
‚úÖ –°–µ—Ä–≤–∏—Å 'minio' –≥–æ—Ç–æ–≤.
==> –û–∂–∏–¥–∞–Ω–∏–µ healthcheck –¥–ª—è —Å–µ—Ä–≤–∏—Å–∞ 'redis' (—Ç–∞–π–º–∞—É—Ç: 60s)...
‚úÖ –°–µ—Ä–≤–∏—Å 'redis' –≥–æ—Ç–æ–≤.
==> –û–∂–∏–¥–∞–Ω–∏–µ healthcheck –¥–ª—è —Å–µ—Ä–≤–∏—Å–∞ 'spark-master' (—Ç–∞–π–º–∞—É—Ç: 60s)...
‚úÖ –°–µ—Ä–≤–∏—Å 'spark-master' –≥–æ—Ç–æ–≤.
==> –û–∂–∏–¥–∞–Ω–∏–µ healthcheck –¥–ª—è —Å–µ—Ä–≤–∏—Å–∞ 'spark-worker-1' (—Ç–∞–π–º–∞—É—Ç: 60s)...
‚úÖ –°–µ—Ä–≤–∏—Å 'spark-worker-1' –≥–æ—Ç–æ–≤.
==> –û–∂–∏–¥–∞–Ω–∏–µ healthcheck –¥–ª—è —Å–µ—Ä–≤–∏—Å–∞ 'kafka' (—Ç–∞–π–º–∞—É—Ç: 60s)...
‚úÖ –°–µ—Ä–≤–∏—Å 'kafka' –≥–æ—Ç–æ–≤.
==> –û–∂–∏–¥–∞–Ω–∏–µ healthcheck –¥–ª—è —Å–µ—Ä–≤–∏—Å–∞ 'mlflow' (—Ç–∞–π–º–∞—É—Ç: 120s)...
‚úÖ –°–µ—Ä–≤–∏—Å 'mlflow' –≥–æ—Ç–æ–≤.
==> –û–∂–∏–¥–∞–Ω–∏–µ healthcheck –¥–ª—è —Å–µ—Ä–≤–∏—Å–∞ 'airflow' (—Ç–∞–π–º–∞—É—Ç: 300s)...
......‚úÖ –°–µ—Ä–≤–∏—Å 'airflow' –≥–æ—Ç–æ–≤.

--- [–≠–¢–ê–ü 4/7] –°–æ–∑–¥–∞–Ω–∏–µ/–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ Airflow ---
[2026-01-18T22:23:18+03:00] –ü–æ–ø—ã—Ç–∫–∞ 1/7: —Å–æ–∑–¥–∞—ë–º/–æ–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è 'mlopsuser' (email: mlopsuser@example.com)...
=== –í—ã–≤–æ–¥ —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ===
/home/airflow/.local/lib/python3.10/site-packages/airflow/configuration.py:724 DeprecationWarning: The auth_backend option in [api] has been renamed to auth_backends - the old setting has been used, but please update your config.
/home/airflow/.local/lib/python3.10/site-packages/airflow/configuration.py:747 DeprecationWarning: The auth_backend option in [api] has been renamed to auth_backends - the old setting has been used, but please update your config.
/home/airflow/.local/lib/python3.10/site-packages/airflow/configuration.py:761 FutureWarning: The auth_backends setting in [api] has had airflow.api.auth.backend.session added in the running config, which is needed by the UI. Please update your config before Apache Airflow 3.0.
/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dag.py:450 DeprecationWarning: The dag_concurrency option in [core] has been renamed to max_active_tasks_per_dag - the old setting has been used, but please update your config.
/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dag.py:3854 DeprecationWarning: The dag_concurrency option in [core] has been renamed to max_active_tasks_per_dag - the old setting has been used, but please update your config.
/home/airflow/.local/lib/python3.10/site-packages/flask_limiter/extension.py:336 UserWarning: Using the in-memory storage for tracking rate limits as no storage was explicitly specified. This is not recommended for production use. See: https://flask-limiter.readthedocs.io#configuring-a-storage-backend for documentation about configuring the storage backend.
[[34m2026-01-18T19:23:20.320+0000[0m] {[34moverride.py:[0m1458} INFO[0m - Added user mlopsuser[0m
User "mlopsuser" created with role "Admin"
=== –ö–æ–Ω–µ—Ü –≤—ã–≤–æ–¥–∞ ===
‚ÑπÔ∏è –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–æ–∑–¥–∞–Ω –∏–ª–∏ —É–∂–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª. –ü—Ä–æ–≤–µ—Ä—è–µ–º API...
‚úÖ API –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞.

--- [–≠–¢–ê–ü 5/7] –û–∂–∏–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ DAG —á–µ—Ä–µ–∑ REST API ---
–û–∂–∏–¥–∞–µ–º, –ø–æ–∫–∞ DAG 'mlops_platform' –Ω–µ –ø–æ—è–≤–∏—Ç—Å—è –≤ API...
‚úÖ DAG 'mlops_platform' –Ω–∞–π–¥–µ–Ω.
–í–∫–ª—é—á–∞–µ–º (unpause) DAG 'mlops_platform'...
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100  1003  100   983  100    20  13999    284 --:--:-- --:--:-- --:--:-- 14328
{
  "dag_id": "mlops_platform",
  "default_view": "grid",
  "description": "Full ML pipeline for MovieLens with model training",
  "file_token": "Ii9vcHQvYWlyZmxvdy9kYWdzL21sb3BzX2RhZy5weSI.J6e22jdPyguvDNk5dB6FdZyuElQ",
  "fileloc": "/opt/airflow/dags/mlops_dag.py",
  "has_import_errors": false,
  "has_task_concurrency_limits": false,
  "is_active": true,
  "is_paused": false,
  "is_subdag": false,
  "last_expired": null,
  "last_parsed_time": "2026-01-18T19:22:59.291948+00:00",
  "last_pickled": null,
  "max_active_runs": 16,
  "max_active_tasks": 2,
  "next_dagrun": null,
  "next_dagrun_create_after": null,
  "next_dagrun_data_interval_end": null,
  "next_dagrun_data_interval_start": null,
  "owners": [
    "student"
  ],
  "pickle_id": null,
  "root_dag_id": null,
  "schedule_interval": null,
  "scheduler_lock": null,
  "tags": [
    {
      "name": "mlops"
    },
    {
      "name": "platform"
    }
  ],
  "timetable_description": "Never, external triggers only"
}
–ó–∞–ø—É—Å–∫–∞–µ–º DAG 'mlops_platform' —Å run_id = api_run_2026-01-18T22:23:21+0300...
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   546  100   496  100    50   5192    523 --:--:-- --:--:-- --:--:--  5747
{
  "conf": {},
  "dag_id": "mlops_platform",
  "dag_run_id": "api_run_2026-01-18T22:23:21+0300",
  "data_interval_end": "2026-01-18T19:23:21.896844+00:00",
  "data_interval_start": "2026-01-18T19:23:21.896844+00:00",
  "end_date": null,
  "execution_date": "2026-01-18T19:23:21.896844+00:00",
  "external_trigger": true,
  "last_scheduling_decision": null,
  "logical_date": "2026-01-18T19:23:21.896844+00:00",
  "note": null,
  "run_type": "manual",
  "start_date": null,
  "state": "queued"
}
–û–∂–∏–¥–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è DAG'–∞...
–°—Ç–∞—Ç—É—Å DAG'–∞: running. –û–∂–∏–¥–∞–µ–º...
–°—Ç–∞—Ç—É—Å DAG'–∞: running. –û–∂–∏–¥–∞–µ–º...
–°—Ç–∞—Ç—É—Å DAG'–∞: running. –û–∂–∏–¥–∞–µ–º...
–°—Ç–∞—Ç—É—Å DAG'–∞: running. –û–∂–∏–¥–∞–µ–º...
–°—Ç–∞—Ç—É—Å DAG'–∞: running. –û–∂–∏–¥–∞–µ–º...
–°—Ç–∞—Ç—É—Å DAG'–∞: running. –û–∂–∏–¥–∞–µ–º...
‚úÖ DAG 'mlops_platform' —É—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω.

--- [–≠–¢–ê–ü 6/7] –ó–∞–ø—É—Å–∫ Model Serving –≤ MLflow ---
–ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Ä–≤–µ—Ä –¥–ª—è –º–æ–¥–µ–ª–∏ 'logistic_regression_movielens' –Ω–∞ –ø–æ—Ä—Ç—É 6000...
–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ –º–æ–¥–µ–ª–∏ (–¥–æ 90 —Å–µ–∫—É–Ω–¥)...
.‚úÖ –°–µ—Ä–≤–µ—Ä –º–æ–¥–µ–ª–∏ –≥–æ—Ç–æ–≤.

--- [–≠–¢–ê–ü 7/7] –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ ---
‚úÖ –ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞, –ø–∞–π–ø–ª–∞–π–Ω –æ–±—É—á–µ–Ω–∏—è –∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å-—Å–µ—Ä–≤–∏—Å –∑–∞–ø—É—â–µ–Ω—ã.
–î–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python3 verify_streaming.py


üéâüéâüéâ –ü–†–û–ï–ö–¢ –£–°–ü–ï–®–ù–û –ó–ê–ü–£–©–ï–ù! üéâüéâüéâ

–¢–æ—á–∫–∏ –¥–æ—Å—Ç—É–ø–∞ –∫ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞–º:
 - MinIO Console:    http://localhost:9001 (minioadmin/minioadmin)
 - Spark Master UI:  http://localhost:8080
 - Spark Worker UI:  http://localhost:8081
 - Airflow UI:       http://localhost:8088 (mlopsuser/mlopspass)
 - MLflow UI:        http://localhost:5000
 - Model Endpoint:   http://localhost:6000/invocations
 - Kafka UI:         http://localhost:8090
 - Kafka:            localhost:29092 (external), kafka:9092 (internal)
 - Redis:            localhost:6379 (no auth)
